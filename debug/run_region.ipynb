{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde0c660-7453-4077-99b0-0a5147a2353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/asun/miniforge3/envs/get/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import wandb\n",
    "from hydra.utils import instantiate\n",
    "from matplotlib import pyplot as plt\n",
    "from minlora import LoRAParametrization\n",
    "from minlora.model import add_lora_by_name\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from get_model.config.config import *\n",
    "from get_model.dataset.zarr_dataset import (\n",
    "    InferenceRegionDataset,\n",
    "    InferenceRegionMotifDataset,\n",
    "    RegionDataset,\n",
    "    RegionMotifDataset,\n",
    "    get_gencode_obj,\n",
    ")\n",
    "from get_model.model.model import *\n",
    "from get_model.model.modules import *\n",
    "from get_model.run import LitModel, run_shared\n",
    "from get_model.utils import (\n",
    "    extract_state_dict,\n",
    "    load_checkpoint,\n",
    "    load_state_dict,\n",
    "    recursive_detach,\n",
    "    recursive_numpy,\n",
    "    rename_state_dict,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c17005-c699-4747-948d-a2b84b76c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_model.run_region import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202e1edb-8a99-4834-be57-12b70c0c4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_model.config.config import export_config, load_config_from_yaml\n",
    "#from get_model.run_region import run_zarr as run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d41bdf7b-ab6e-47b1-a51f-e2f125c811ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config_from_yaml(\"/gpfs/home/asun/jin_lab/get/debug/interpret_gex_finetune_config.yaml\")\n",
    "cfg.finetune.checkpoint = cfg.finetune.resume_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73a8d577-7381-4612-b02c-c6653421c77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ckpt from /gpfs/home/asun/jin_lab/get/3_aggr_m23_finetune/output/finetune_aggr_multiome/training_from_null_m23_L6-IT_Astro_no_chr_split_binary_atac/checkpoints/best.ckpt\n",
      "Load state_dict by model_key = state_dict\n"
     ]
    }
   ],
   "source": [
    "model = RegionLitModel(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a854aac-53f1-4164-b878-05193a82e353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token: torch.Size([1, 1, 768]), mean=-0.0084, std=0.0649\n",
      "region_embed.embed.weight: torch.Size([768, 283]), mean=-0.0008, std=0.0686\n",
      "region_embed.embed.bias: torch.Size([768]), mean=0.0052, std=0.0515\n",
      "encoder.blocks.0.norm1.weight: torch.Size([768]), mean=0.6558, std=0.1529\n",
      "encoder.blocks.0.norm1.bias: torch.Size([768]), mean=0.0231, std=0.3234\n",
      "encoder.blocks.0.attn.q_bias: torch.Size([768]), mean=0.0057, std=0.1651\n",
      "encoder.blocks.0.attn.v_bias: torch.Size([768]), mean=-0.0008, std=0.0363\n",
      "encoder.blocks.0.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0001, std=0.0265\n",
      "encoder.blocks.0.attn.proj.weight: torch.Size([768, 768]), mean=0.0001, std=0.0254\n",
      "encoder.blocks.0.attn.proj.bias: torch.Size([768]), mean=0.0067, std=0.0544\n",
      "encoder.blocks.0.norm2.weight: torch.Size([768]), mean=0.9401, std=0.6096\n",
      "encoder.blocks.0.norm2.bias: torch.Size([768]), mean=-0.0101, std=0.0633\n",
      "encoder.blocks.0.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0004, std=0.0364\n",
      "encoder.blocks.0.mlp.fc1.bias: torch.Size([3072]), mean=-0.0488, std=0.0677\n",
      "encoder.blocks.0.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0307\n",
      "encoder.blocks.0.mlp.fc2.bias: torch.Size([768]), mean=0.0003, std=0.0479\n",
      "encoder.blocks.1.norm1.weight: torch.Size([768]), mean=0.6392, std=0.0839\n",
      "encoder.blocks.1.norm1.bias: torch.Size([768]), mean=-0.0032, std=0.0988\n",
      "encoder.blocks.1.attn.q_bias: torch.Size([768]), mean=0.0002, std=0.1035\n",
      "encoder.blocks.1.attn.v_bias: torch.Size([768]), mean=-0.0000, std=0.0117\n",
      "encoder.blocks.1.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0314\n",
      "encoder.blocks.1.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0265\n",
      "encoder.blocks.1.attn.proj.bias: torch.Size([768]), mean=-0.0004, std=0.0369\n",
      "encoder.blocks.1.norm2.weight: torch.Size([768]), mean=0.8779, std=0.2269\n",
      "encoder.blocks.1.norm2.bias: torch.Size([768]), mean=-0.0016, std=0.0875\n",
      "encoder.blocks.1.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0002, std=0.0355\n",
      "encoder.blocks.1.mlp.fc1.bias: torch.Size([3072]), mean=-0.0542, std=0.0232\n",
      "encoder.blocks.1.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0342\n",
      "encoder.blocks.1.mlp.fc2.bias: torch.Size([768]), mean=-0.0000, std=0.0339\n",
      "encoder.blocks.2.norm1.weight: torch.Size([768]), mean=0.8371, std=0.0735\n",
      "encoder.blocks.2.norm1.bias: torch.Size([768]), mean=-0.0081, std=0.1200\n",
      "encoder.blocks.2.attn.q_bias: torch.Size([768]), mean=-0.0001, std=0.0876\n",
      "encoder.blocks.2.attn.v_bias: torch.Size([768]), mean=0.0006, std=0.0206\n",
      "encoder.blocks.2.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0367\n",
      "encoder.blocks.2.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0269\n",
      "encoder.blocks.2.attn.proj.bias: torch.Size([768]), mean=0.0000, std=0.0454\n",
      "encoder.blocks.2.norm2.weight: torch.Size([768]), mean=1.2199, std=0.1509\n",
      "encoder.blocks.2.norm2.bias: torch.Size([768]), mean=-0.0064, std=0.1478\n",
      "encoder.blocks.2.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0001, std=0.0358\n",
      "encoder.blocks.2.mlp.fc1.bias: torch.Size([3072]), mean=-0.0586, std=0.0163\n",
      "encoder.blocks.2.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0317\n",
      "encoder.blocks.2.mlp.fc2.bias: torch.Size([768]), mean=0.0003, std=0.0422\n",
      "encoder.blocks.3.norm1.weight: torch.Size([768]), mean=0.8676, std=0.0844\n",
      "encoder.blocks.3.norm1.bias: torch.Size([768]), mean=-0.0090, std=0.0772\n",
      "encoder.blocks.3.attn.q_bias: torch.Size([768]), mean=0.0023, std=0.1015\n",
      "encoder.blocks.3.attn.v_bias: torch.Size([768]), mean=-0.0003, std=0.0214\n",
      "encoder.blocks.3.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0327\n",
      "encoder.blocks.3.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0275\n",
      "encoder.blocks.3.attn.proj.bias: torch.Size([768]), mean=-0.0001, std=0.0441\n",
      "encoder.blocks.3.norm2.weight: torch.Size([768]), mean=1.0391, std=0.0869\n",
      "encoder.blocks.3.norm2.bias: torch.Size([768]), mean=-0.0062, std=0.1322\n",
      "encoder.blocks.3.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0001, std=0.0356\n",
      "encoder.blocks.3.mlp.fc1.bias: torch.Size([3072]), mean=-0.0669, std=0.0245\n",
      "encoder.blocks.3.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0000, std=0.0331\n",
      "encoder.blocks.3.mlp.fc2.bias: torch.Size([768]), mean=-0.0000, std=0.0367\n",
      "encoder.blocks.4.norm1.weight: torch.Size([768]), mean=0.8582, std=0.0616\n",
      "encoder.blocks.4.norm1.bias: torch.Size([768]), mean=-0.0161, std=0.0617\n",
      "encoder.blocks.4.attn.q_bias: torch.Size([768]), mean=0.0107, std=0.1669\n",
      "encoder.blocks.4.attn.v_bias: torch.Size([768]), mean=0.0006, std=0.0144\n",
      "encoder.blocks.4.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0347\n",
      "encoder.blocks.4.attn.proj.weight: torch.Size([768, 768]), mean=-0.0000, std=0.0280\n",
      "encoder.blocks.4.attn.proj.bias: torch.Size([768]), mean=0.0001, std=0.0528\n",
      "encoder.blocks.4.norm2.weight: torch.Size([768]), mean=1.0080, std=0.0749\n",
      "encoder.blocks.4.norm2.bias: torch.Size([768]), mean=-0.0083, std=0.1108\n",
      "encoder.blocks.4.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0001, std=0.0352\n",
      "encoder.blocks.4.mlp.fc1.bias: torch.Size([3072]), mean=-0.0674, std=0.0241\n",
      "encoder.blocks.4.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0000, std=0.0360\n",
      "encoder.blocks.4.mlp.fc2.bias: torch.Size([768]), mean=-0.0000, std=0.0398\n",
      "encoder.blocks.5.norm1.weight: torch.Size([768]), mean=0.9420, std=0.0740\n",
      "encoder.blocks.5.norm1.bias: torch.Size([768]), mean=-0.0216, std=0.0672\n",
      "encoder.blocks.5.attn.q_bias: torch.Size([768]), mean=-0.0011, std=0.1857\n",
      "encoder.blocks.5.attn.v_bias: torch.Size([768]), mean=-0.0009, std=0.0157\n",
      "encoder.blocks.5.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0000, std=0.0349\n",
      "encoder.blocks.5.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0286\n",
      "encoder.blocks.5.attn.proj.bias: torch.Size([768]), mean=0.0002, std=0.0565\n",
      "encoder.blocks.5.norm2.weight: torch.Size([768]), mean=1.0073, std=0.0662\n",
      "encoder.blocks.5.norm2.bias: torch.Size([768]), mean=-0.0081, std=0.0965\n",
      "encoder.blocks.5.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0002, std=0.0351\n",
      "encoder.blocks.5.mlp.fc1.bias: torch.Size([3072]), mean=-0.0730, std=0.0289\n",
      "encoder.blocks.5.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0374\n",
      "encoder.blocks.5.mlp.fc2.bias: torch.Size([768]), mean=0.0003, std=0.0624\n",
      "encoder.blocks.6.norm1.weight: torch.Size([768]), mean=0.9888, std=0.0769\n",
      "encoder.blocks.6.norm1.bias: torch.Size([768]), mean=-0.0253, std=0.0820\n",
      "encoder.blocks.6.attn.q_bias: torch.Size([768]), mean=-0.0033, std=0.1949\n",
      "encoder.blocks.6.attn.v_bias: torch.Size([768]), mean=0.0001, std=0.0237\n",
      "encoder.blocks.6.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0353\n",
      "encoder.blocks.6.attn.proj.weight: torch.Size([768, 768]), mean=-0.0000, std=0.0288\n",
      "encoder.blocks.6.attn.proj.bias: torch.Size([768]), mean=0.0008, std=0.0727\n",
      "encoder.blocks.6.norm2.weight: torch.Size([768]), mean=1.0137, std=0.0589\n",
      "encoder.blocks.6.norm2.bias: torch.Size([768]), mean=-0.0066, std=0.1028\n",
      "encoder.blocks.6.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0002, std=0.0363\n",
      "encoder.blocks.6.mlp.fc1.bias: torch.Size([3072]), mean=-0.0769, std=0.0377\n",
      "encoder.blocks.6.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0384\n",
      "encoder.blocks.6.mlp.fc2.bias: torch.Size([768]), mean=0.0009, std=0.0862\n",
      "encoder.blocks.7.norm1.weight: torch.Size([768]), mean=1.0358, std=0.0753\n",
      "encoder.blocks.7.norm1.bias: torch.Size([768]), mean=-0.0187, std=0.0679\n",
      "encoder.blocks.7.attn.q_bias: torch.Size([768]), mean=0.0070, std=0.2289\n",
      "encoder.blocks.7.attn.v_bias: torch.Size([768]), mean=-0.0013, std=0.0242\n",
      "encoder.blocks.7.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0350\n",
      "encoder.blocks.7.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0297\n",
      "encoder.blocks.7.attn.proj.bias: torch.Size([768]), mean=0.0010, std=0.0755\n",
      "encoder.blocks.7.norm2.weight: torch.Size([768]), mean=1.0167, std=0.0677\n",
      "encoder.blocks.7.norm2.bias: torch.Size([768]), mean=-0.0056, std=0.1066\n",
      "encoder.blocks.7.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0003, std=0.0367\n",
      "encoder.blocks.7.mlp.fc1.bias: torch.Size([3072]), mean=-0.0746, std=0.0433\n",
      "encoder.blocks.7.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0398\n",
      "encoder.blocks.7.mlp.fc2.bias: torch.Size([768]), mean=0.0009, std=0.0677\n",
      "encoder.blocks.8.norm1.weight: torch.Size([768]), mean=1.0760, std=0.0743\n",
      "encoder.blocks.8.norm1.bias: torch.Size([768]), mean=-0.0178, std=0.0735\n",
      "encoder.blocks.8.attn.q_bias: torch.Size([768]), mean=-0.0100, std=0.2226\n",
      "encoder.blocks.8.attn.v_bias: torch.Size([768]), mean=0.0005, std=0.0196\n",
      "encoder.blocks.8.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0358\n",
      "encoder.blocks.8.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0304\n",
      "encoder.blocks.8.attn.proj.bias: torch.Size([768]), mean=0.0006, std=0.0721\n",
      "encoder.blocks.8.norm2.weight: torch.Size([768]), mean=1.0606, std=0.0673\n",
      "encoder.blocks.8.norm2.bias: torch.Size([768]), mean=-0.0046, std=0.1101\n",
      "encoder.blocks.8.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0005, std=0.0389\n",
      "encoder.blocks.8.mlp.fc1.bias: torch.Size([3072]), mean=-0.0776, std=0.0477\n",
      "encoder.blocks.8.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0420\n",
      "encoder.blocks.8.mlp.fc2.bias: torch.Size([768]), mean=0.0002, std=0.0651\n",
      "encoder.blocks.9.norm1.weight: torch.Size([768]), mean=1.0891, std=0.0762\n",
      "encoder.blocks.9.norm1.bias: torch.Size([768]), mean=-0.0175, std=0.0784\n",
      "encoder.blocks.9.attn.q_bias: torch.Size([768]), mean=0.0047, std=0.2063\n",
      "encoder.blocks.9.attn.v_bias: torch.Size([768]), mean=0.0004, std=0.0190\n",
      "encoder.blocks.9.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0000, std=0.0374\n",
      "encoder.blocks.9.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0319\n",
      "encoder.blocks.9.attn.proj.bias: torch.Size([768]), mean=-0.0001, std=0.0822\n",
      "encoder.blocks.9.norm2.weight: torch.Size([768]), mean=1.1061, std=0.0668\n",
      "encoder.blocks.9.norm2.bias: torch.Size([768]), mean=-0.0020, std=0.1293\n",
      "encoder.blocks.9.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0007, std=0.0419\n",
      "encoder.blocks.9.mlp.fc1.bias: torch.Size([3072]), mean=-0.0785, std=0.0581\n",
      "encoder.blocks.9.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0459\n",
      "encoder.blocks.9.mlp.fc2.bias: torch.Size([768]), mean=-0.0001, std=0.0751\n",
      "encoder.blocks.10.norm1.weight: torch.Size([768]), mean=1.0688, std=0.0786\n",
      "encoder.blocks.10.norm1.bias: torch.Size([768]), mean=-0.0157, std=0.0839\n",
      "encoder.blocks.10.attn.q_bias: torch.Size([768]), mean=0.0072, std=0.1788\n",
      "encoder.blocks.10.attn.v_bias: torch.Size([768]), mean=-0.0004, std=0.0206\n",
      "encoder.blocks.10.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0000, std=0.0395\n",
      "encoder.blocks.10.attn.proj.weight: torch.Size([768, 768]), mean=-0.0000, std=0.0327\n",
      "encoder.blocks.10.attn.proj.bias: torch.Size([768]), mean=-0.0002, std=0.0994\n",
      "encoder.blocks.10.norm2.weight: torch.Size([768]), mean=1.1809, std=0.0673\n",
      "encoder.blocks.10.norm2.bias: torch.Size([768]), mean=-0.0043, std=0.1799\n",
      "encoder.blocks.10.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0006, std=0.0448\n",
      "encoder.blocks.10.mlp.fc1.bias: torch.Size([3072]), mean=-0.0806, std=0.0666\n",
      "encoder.blocks.10.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0497\n",
      "encoder.blocks.10.mlp.fc2.bias: torch.Size([768]), mean=0.0003, std=0.0798\n",
      "encoder.blocks.11.norm1.weight: torch.Size([768]), mean=0.9105, std=0.0716\n",
      "encoder.blocks.11.norm1.bias: torch.Size([768]), mean=-0.0117, std=0.1044\n",
      "encoder.blocks.11.attn.q_bias: torch.Size([768]), mean=-0.0021, std=0.1530\n",
      "encoder.blocks.11.attn.v_bias: torch.Size([768]), mean=0.0006, std=0.0275\n",
      "encoder.blocks.11.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0000, std=0.0383\n",
      "encoder.blocks.11.attn.proj.weight: torch.Size([768, 768]), mean=-0.0000, std=0.0328\n",
      "encoder.blocks.11.attn.proj.bias: torch.Size([768]), mean=-0.0014, std=0.0805\n",
      "encoder.blocks.11.norm2.weight: torch.Size([768]), mean=1.7583, std=0.1286\n",
      "encoder.blocks.11.norm2.bias: torch.Size([768]), mean=-0.0060, std=0.1764\n",
      "encoder.blocks.11.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0006, std=0.0425\n",
      "encoder.blocks.11.mlp.fc1.bias: torch.Size([3072]), mean=-0.0712, std=0.0855\n",
      "encoder.blocks.11.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0001, std=0.0411\n",
      "encoder.blocks.11.mlp.fc2.bias: torch.Size([768]), mean=0.0002, std=0.0506\n",
      "encoder.norm.weight: torch.Size([768]), mean=0.8882, std=0.1179\n",
      "encoder.norm.bias: torch.Size([768]), mean=-0.0035, std=0.0749\n",
      "head_exp.head.weight: torch.Size([2, 768]), mean=-0.0002, std=0.0188\n",
      "head_exp.head.bias: torch.Size([2]), mean=-0.0386, std=0.0003\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}, mean={param.data.mean():.4f}, std={param.data.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f98aca8-c563-4f50-85c2-fea525b503fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 85,267,202\n",
      "Frozen params: 0\n"
     ]
    }
   ],
   "source": [
    "trainable = sum(p.numel() for p in model.model.parameters() if p.requires_grad)\n",
    "frozen = sum(p.numel() for p in model.model.parameters() if not p.requires_grad)\n",
    "print(f\"Trainable params: {trainable:,}\")\n",
    "print(f\"Frozen params: {frozen:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27534127-fc71-48ea-a549-7714127d0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegionLitModel(cfg)\n",
    "logging.debug(OmegaConf.to_yaml(cfg))\n",
    "dm = RegionDataModule(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de136f3f-cc63-4065-a72c-eda9e6008814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ckpt from /gpfs/home/asun/jin_lab/get/3_aggr_m23_finetune/checkpoint-best.pth\n",
      "Load state_dict by model_key = model\n"
     ]
    }
   ],
   "source": [
    "pretrain_cfg = load_config_from_yaml(\"/gpfs/home/asun/jin_lab/get/3_aggr_m23_finetune/gex_batac_config.yaml\")\n",
    "pretrain_model = RegionLitModel(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "341ee2f8-6c5e-4cca-bc59-bc66eba6339b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token: torch.Size([1, 1, 768]), mean=-0.0087, std=0.0610\n",
      "region_embed.embed.weight: torch.Size([768, 283]), mean=0.0010, std=0.0705\n",
      "region_embed.embed.bias: torch.Size([768]), mean=0.0068, std=0.0521\n",
      "encoder.blocks.0.norm1.weight: torch.Size([768]), mean=0.6721, std=0.1583\n",
      "encoder.blocks.0.norm1.bias: torch.Size([768]), mean=0.0234, std=0.3330\n",
      "encoder.blocks.0.attn.q_bias: torch.Size([768]), mean=0.0054, std=0.1649\n",
      "encoder.blocks.0.attn.v_bias: torch.Size([768]), mean=-0.0008, std=0.0364\n",
      "encoder.blocks.0.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0001, std=0.0285\n",
      "encoder.blocks.0.attn.proj.weight: torch.Size([768, 768]), mean=0.0001, std=0.0290\n",
      "encoder.blocks.0.attn.proj.bias: torch.Size([768]), mean=0.0076, std=0.0518\n",
      "encoder.blocks.0.norm2.weight: torch.Size([768]), mean=0.9471, std=0.6040\n",
      "encoder.blocks.0.norm2.bias: torch.Size([768]), mean=-0.0100, std=0.0643\n",
      "encoder.blocks.0.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0004, std=0.0379\n",
      "encoder.blocks.0.mlp.fc1.bias: torch.Size([3072]), mean=-0.0483, std=0.0635\n",
      "encoder.blocks.0.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0314\n",
      "encoder.blocks.0.mlp.fc2.bias: torch.Size([768]), mean=0.0004, std=0.0470\n",
      "encoder.blocks.1.norm1.weight: torch.Size([768]), mean=0.6468, std=0.0867\n",
      "encoder.blocks.1.norm1.bias: torch.Size([768]), mean=-0.0028, std=0.0971\n",
      "encoder.blocks.1.attn.q_bias: torch.Size([768]), mean=0.0002, std=0.1031\n",
      "encoder.blocks.1.attn.v_bias: torch.Size([768]), mean=0.0001, std=0.0114\n",
      "encoder.blocks.1.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0330\n",
      "encoder.blocks.1.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0271\n",
      "encoder.blocks.1.attn.proj.bias: torch.Size([768]), mean=-0.0004, std=0.0379\n",
      "encoder.blocks.1.norm2.weight: torch.Size([768]), mean=0.8711, std=0.2267\n",
      "encoder.blocks.1.norm2.bias: torch.Size([768]), mean=-0.0017, std=0.0766\n",
      "encoder.blocks.1.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0002, std=0.0363\n",
      "encoder.blocks.1.mlp.fc1.bias: torch.Size([3072]), mean=-0.0505, std=0.0233\n",
      "encoder.blocks.1.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0349\n",
      "encoder.blocks.1.mlp.fc2.bias: torch.Size([768]), mean=0.0000, std=0.0335\n",
      "encoder.blocks.2.norm1.weight: torch.Size([768]), mean=0.8622, std=0.0740\n",
      "encoder.blocks.2.norm1.bias: torch.Size([768]), mean=-0.0078, std=0.1143\n",
      "encoder.blocks.2.attn.q_bias: torch.Size([768]), mean=-0.0007, std=0.0904\n",
      "encoder.blocks.2.attn.v_bias: torch.Size([768]), mean=0.0006, std=0.0206\n",
      "encoder.blocks.2.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0386\n",
      "encoder.blocks.2.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0276\n",
      "encoder.blocks.2.attn.proj.bias: torch.Size([768]), mean=0.0001, std=0.0440\n",
      "encoder.blocks.2.norm2.weight: torch.Size([768]), mean=1.2200, std=0.1486\n",
      "encoder.blocks.2.norm2.bias: torch.Size([768]), mean=-0.0066, std=0.1401\n",
      "encoder.blocks.2.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0001, std=0.0368\n",
      "encoder.blocks.2.mlp.fc1.bias: torch.Size([3072]), mean=-0.0556, std=0.0160\n",
      "encoder.blocks.2.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0321\n",
      "encoder.blocks.2.mlp.fc2.bias: torch.Size([768]), mean=0.0003, std=0.0407\n",
      "encoder.blocks.3.norm1.weight: torch.Size([768]), mean=0.8917, std=0.0851\n",
      "encoder.blocks.3.norm1.bias: torch.Size([768]), mean=-0.0088, std=0.0720\n",
      "encoder.blocks.3.attn.q_bias: torch.Size([768]), mean=0.0024, std=0.0980\n",
      "encoder.blocks.3.attn.v_bias: torch.Size([768]), mean=-0.0004, std=0.0218\n",
      "encoder.blocks.3.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0339\n",
      "encoder.blocks.3.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0285\n",
      "encoder.blocks.3.attn.proj.bias: torch.Size([768]), mean=-0.0001, std=0.0419\n",
      "encoder.blocks.3.norm2.weight: torch.Size([768]), mean=1.0323, std=0.0846\n",
      "encoder.blocks.3.norm2.bias: torch.Size([768]), mean=-0.0065, std=0.1240\n",
      "encoder.blocks.3.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0001, std=0.0364\n",
      "encoder.blocks.3.mlp.fc1.bias: torch.Size([3072]), mean=-0.0642, std=0.0250\n",
      "encoder.blocks.3.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0000, std=0.0336\n",
      "encoder.blocks.3.mlp.fc2.bias: torch.Size([768]), mean=0.0000, std=0.0354\n",
      "encoder.blocks.4.norm1.weight: torch.Size([768]), mean=0.8726, std=0.0608\n",
      "encoder.blocks.4.norm1.bias: torch.Size([768]), mean=-0.0163, std=0.0611\n",
      "encoder.blocks.4.attn.q_bias: torch.Size([768]), mean=0.0111, std=0.1636\n",
      "encoder.blocks.4.attn.v_bias: torch.Size([768]), mean=0.0007, std=0.0142\n",
      "encoder.blocks.4.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0359\n",
      "encoder.blocks.4.attn.proj.weight: torch.Size([768, 768]), mean=-0.0000, std=0.0289\n",
      "encoder.blocks.4.attn.proj.bias: torch.Size([768]), mean=0.0001, std=0.0528\n",
      "encoder.blocks.4.norm2.weight: torch.Size([768]), mean=0.9998, std=0.0723\n",
      "encoder.blocks.4.norm2.bias: torch.Size([768]), mean=-0.0084, std=0.1057\n",
      "encoder.blocks.4.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0001, std=0.0359\n",
      "encoder.blocks.4.mlp.fc1.bias: torch.Size([3072]), mean=-0.0653, std=0.0245\n",
      "encoder.blocks.4.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0000, std=0.0370\n",
      "encoder.blocks.4.mlp.fc2.bias: torch.Size([768]), mean=0.0000, std=0.0380\n",
      "encoder.blocks.5.norm1.weight: torch.Size([768]), mean=0.9566, std=0.0728\n",
      "encoder.blocks.5.norm1.bias: torch.Size([768]), mean=-0.0220, std=0.0678\n",
      "encoder.blocks.5.attn.q_bias: torch.Size([768]), mean=-0.0015, std=0.1833\n",
      "encoder.blocks.5.attn.v_bias: torch.Size([768]), mean=-0.0008, std=0.0154\n",
      "encoder.blocks.5.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0000, std=0.0361\n",
      "encoder.blocks.5.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0296\n",
      "encoder.blocks.5.attn.proj.bias: torch.Size([768]), mean=0.0003, std=0.0556\n",
      "encoder.blocks.5.norm2.weight: torch.Size([768]), mean=1.0011, std=0.0644\n",
      "encoder.blocks.5.norm2.bias: torch.Size([768]), mean=-0.0084, std=0.0914\n",
      "encoder.blocks.5.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0002, std=0.0359\n",
      "encoder.blocks.5.mlp.fc1.bias: torch.Size([3072]), mean=-0.0706, std=0.0293\n",
      "encoder.blocks.5.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0000, std=0.0386\n",
      "encoder.blocks.5.mlp.fc2.bias: torch.Size([768]), mean=0.0004, std=0.0591\n",
      "encoder.blocks.6.norm1.weight: torch.Size([768]), mean=1.0049, std=0.0762\n",
      "encoder.blocks.6.norm1.bias: torch.Size([768]), mean=-0.0255, std=0.0811\n",
      "encoder.blocks.6.attn.q_bias: torch.Size([768]), mean=-0.0031, std=0.1927\n",
      "encoder.blocks.6.attn.v_bias: torch.Size([768]), mean=0.0001, std=0.0231\n",
      "encoder.blocks.6.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0367\n",
      "encoder.blocks.6.attn.proj.weight: torch.Size([768, 768]), mean=-0.0000, std=0.0299\n",
      "encoder.blocks.6.attn.proj.bias: torch.Size([768]), mean=0.0008, std=0.0708\n",
      "encoder.blocks.6.norm2.weight: torch.Size([768]), mean=1.0070, std=0.0566\n",
      "encoder.blocks.6.norm2.bias: torch.Size([768]), mean=-0.0068, std=0.0988\n",
      "encoder.blocks.6.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0002, std=0.0371\n",
      "encoder.blocks.6.mlp.fc1.bias: torch.Size([3072]), mean=-0.0748, std=0.0374\n",
      "encoder.blocks.6.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0000, std=0.0398\n",
      "encoder.blocks.6.mlp.fc2.bias: torch.Size([768]), mean=0.0008, std=0.0835\n",
      "encoder.blocks.7.norm1.weight: torch.Size([768]), mean=1.0532, std=0.0750\n",
      "encoder.blocks.7.norm1.bias: torch.Size([768]), mean=-0.0183, std=0.0666\n",
      "encoder.blocks.7.attn.q_bias: torch.Size([768]), mean=0.0065, std=0.2269\n",
      "encoder.blocks.7.attn.v_bias: torch.Size([768]), mean=-0.0011, std=0.0238\n",
      "encoder.blocks.7.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0365\n",
      "encoder.blocks.7.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0311\n",
      "encoder.blocks.7.attn.proj.bias: torch.Size([768]), mean=0.0009, std=0.0739\n",
      "encoder.blocks.7.norm2.weight: torch.Size([768]), mean=1.0102, std=0.0656\n",
      "encoder.blocks.7.norm2.bias: torch.Size([768]), mean=-0.0057, std=0.1030\n",
      "encoder.blocks.7.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0003, std=0.0376\n",
      "encoder.blocks.7.mlp.fc1.bias: torch.Size([3072]), mean=-0.0729, std=0.0434\n",
      "encoder.blocks.7.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0000, std=0.0413\n",
      "encoder.blocks.7.mlp.fc2.bias: torch.Size([768]), mean=0.0008, std=0.0658\n",
      "encoder.blocks.8.norm1.weight: torch.Size([768]), mean=1.0949, std=0.0743\n",
      "encoder.blocks.8.norm1.bias: torch.Size([768]), mean=-0.0173, std=0.0721\n",
      "encoder.blocks.8.attn.q_bias: torch.Size([768]), mean=-0.0098, std=0.2209\n",
      "encoder.blocks.8.attn.v_bias: torch.Size([768]), mean=0.0004, std=0.0194\n",
      "encoder.blocks.8.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0000, std=0.0375\n",
      "encoder.blocks.8.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0320\n",
      "encoder.blocks.8.attn.proj.bias: torch.Size([768]), mean=0.0006, std=0.0714\n",
      "encoder.blocks.8.norm2.weight: torch.Size([768]), mean=1.0554, std=0.0665\n",
      "encoder.blocks.8.norm2.bias: torch.Size([768]), mean=-0.0047, std=0.1072\n",
      "encoder.blocks.8.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0005, std=0.0401\n",
      "encoder.blocks.8.mlp.fc1.bias: torch.Size([3072]), mean=-0.0765, std=0.0478\n",
      "encoder.blocks.8.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0438\n",
      "encoder.blocks.8.mlp.fc2.bias: torch.Size([768]), mean=0.0002, std=0.0634\n",
      "encoder.blocks.9.norm1.weight: torch.Size([768]), mean=1.1075, std=0.0753\n",
      "encoder.blocks.9.norm1.bias: torch.Size([768]), mean=-0.0171, std=0.0773\n",
      "encoder.blocks.9.attn.q_bias: torch.Size([768]), mean=0.0048, std=0.2048\n",
      "encoder.blocks.9.attn.v_bias: torch.Size([768]), mean=0.0004, std=0.0189\n",
      "encoder.blocks.9.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0000, std=0.0393\n",
      "encoder.blocks.9.attn.proj.weight: torch.Size([768, 768]), mean=0.0000, std=0.0337\n",
      "encoder.blocks.9.attn.proj.bias: torch.Size([768]), mean=-0.0001, std=0.0820\n",
      "encoder.blocks.9.norm2.weight: torch.Size([768]), mean=1.1027, std=0.0657\n",
      "encoder.blocks.9.norm2.bias: torch.Size([768]), mean=-0.0019, std=0.1291\n",
      "encoder.blocks.9.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0007, std=0.0435\n",
      "encoder.blocks.9.mlp.fc1.bias: torch.Size([3072]), mean=-0.0780, std=0.0583\n",
      "encoder.blocks.9.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0000, std=0.0480\n",
      "encoder.blocks.9.mlp.fc2.bias: torch.Size([768]), mean=-0.0002, std=0.0734\n",
      "encoder.blocks.10.norm1.weight: torch.Size([768]), mean=1.0858, std=0.0777\n",
      "encoder.blocks.10.norm1.bias: torch.Size([768]), mean=-0.0156, std=0.0826\n",
      "encoder.blocks.10.attn.q_bias: torch.Size([768]), mean=0.0074, std=0.1788\n",
      "encoder.blocks.10.attn.v_bias: torch.Size([768]), mean=-0.0003, std=0.0205\n",
      "encoder.blocks.10.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0000, std=0.0416\n",
      "encoder.blocks.10.attn.proj.weight: torch.Size([768, 768]), mean=-0.0000, std=0.0347\n",
      "encoder.blocks.10.attn.proj.bias: torch.Size([768]), mean=-0.0002, std=0.0985\n",
      "encoder.blocks.10.norm2.weight: torch.Size([768]), mean=1.1792, std=0.0657\n",
      "encoder.blocks.10.norm2.bias: torch.Size([768]), mean=-0.0042, std=0.1813\n",
      "encoder.blocks.10.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0006, std=0.0468\n",
      "encoder.blocks.10.mlp.fc1.bias: torch.Size([3072]), mean=-0.0801, std=0.0666\n",
      "encoder.blocks.10.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.0522\n",
      "encoder.blocks.10.mlp.fc2.bias: torch.Size([768]), mean=0.0002, std=0.0784\n",
      "encoder.blocks.11.norm1.weight: torch.Size([768]), mean=0.9235, std=0.0711\n",
      "encoder.blocks.11.norm1.bias: torch.Size([768]), mean=-0.0117, std=0.1040\n",
      "encoder.blocks.11.attn.q_bias: torch.Size([768]), mean=-0.0023, std=0.1529\n",
      "encoder.blocks.11.attn.v_bias: torch.Size([768]), mean=0.0005, std=0.0274\n",
      "encoder.blocks.11.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0000, std=0.0402\n",
      "encoder.blocks.11.attn.proj.weight: torch.Size([768, 768]), mean=-0.0000, std=0.0349\n",
      "encoder.blocks.11.attn.proj.bias: torch.Size([768]), mean=-0.0014, std=0.0789\n",
      "encoder.blocks.11.norm2.weight: torch.Size([768]), mean=1.7582, std=0.1281\n",
      "encoder.blocks.11.norm2.bias: torch.Size([768]), mean=-0.0061, std=0.1760\n",
      "encoder.blocks.11.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0006, std=0.0444\n",
      "encoder.blocks.11.mlp.fc1.bias: torch.Size([3072]), mean=-0.0700, std=0.0855\n",
      "encoder.blocks.11.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0000, std=0.0426\n",
      "encoder.blocks.11.mlp.fc2.bias: torch.Size([768]), mean=0.0001, std=0.0486\n",
      "encoder.norm.weight: torch.Size([768]), mean=0.9116, std=0.1078\n",
      "encoder.norm.bias: torch.Size([768]), mean=-0.0035, std=0.0681\n",
      "head_exp.head.weight: torch.Size([2, 768]), mean=-0.0002, std=0.0199\n",
      "head_exp.head.bias: torch.Size([2]), mean=-0.0339, std=0.0005\n"
     ]
    }
   ],
   "source": [
    "for name, param in pretrain_model.model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}, mean={param.data.mean():.4f}, std={param.data.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd968ffa-0ea0-4217-9695-8b5aa6bd479f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 163 layers with differences:\n",
      "model.cls_token: mean diff = 0.009539\n",
      "model.region_embed.embed.weight: mean diff = 0.008947\n",
      "model.region_embed.embed.bias: mean diff = 0.010705\n",
      "model.encoder.blocks.0.norm1.weight: mean diff = 0.018320\n",
      "model.encoder.blocks.0.norm1.bias: mean diff = 0.013663\n",
      "model.encoder.blocks.0.attn.q_bias: mean diff = 0.003213\n",
      "model.encoder.blocks.0.attn.v_bias: mean diff = 0.000879\n",
      "model.encoder.blocks.0.attn.qkv.weight: mean diff = 0.004645\n",
      "model.encoder.blocks.0.attn.proj.weight: mean diff = 0.005826\n",
      "model.encoder.blocks.0.attn.proj.bias: mean diff = 0.007022\n",
      "model.encoder.blocks.0.norm2.weight: mean diff = 0.009941\n",
      "model.encoder.blocks.0.norm2.bias: mean diff = 0.008237\n",
      "model.encoder.blocks.0.mlp.fc1.weight: mean diff = 0.006207\n",
      "model.encoder.blocks.0.mlp.fc1.bias: mean diff = 0.005597\n",
      "model.encoder.blocks.0.mlp.fc2.weight: mean diff = 0.006096\n",
      "model.encoder.blocks.0.mlp.fc2.bias: mean diff = 0.003280\n",
      "model.encoder.blocks.1.norm1.weight: mean diff = 0.010385\n",
      "model.encoder.blocks.1.norm1.bias: mean diff = 0.009469\n",
      "model.encoder.blocks.1.attn.q_bias: mean diff = 0.010309\n",
      "model.encoder.blocks.1.attn.v_bias: mean diff = 0.002861\n",
      "model.encoder.blocks.1.attn.qkv.weight: mean diff = 0.006738\n",
      "model.encoder.blocks.1.attn.proj.weight: mean diff = 0.005800\n",
      "model.encoder.blocks.1.attn.proj.bias: mean diff = 0.004727\n",
      "model.encoder.blocks.1.norm2.weight: mean diff = 0.009589\n",
      "model.encoder.blocks.1.norm2.bias: mean diff = 0.011316\n",
      "model.encoder.blocks.1.mlp.fc1.weight: mean diff = 0.007444\n",
      "model.encoder.blocks.1.mlp.fc1.bias: mean diff = 0.004835\n",
      "model.encoder.blocks.1.mlp.fc2.weight: mean diff = 0.008108\n",
      "model.encoder.blocks.1.mlp.fc2.bias: mean diff = 0.004433\n",
      "model.encoder.blocks.2.norm1.weight: mean diff = 0.025038\n",
      "model.encoder.blocks.2.norm1.bias: mean diff = 0.012290\n",
      "model.encoder.blocks.2.attn.q_bias: mean diff = 0.007963\n",
      "model.encoder.blocks.2.attn.v_bias: mean diff = 0.002884\n",
      "model.encoder.blocks.2.attn.qkv.weight: mean diff = 0.007511\n",
      "model.encoder.blocks.2.attn.proj.weight: mean diff = 0.006763\n",
      "model.encoder.blocks.2.attn.proj.bias: mean diff = 0.004636\n",
      "model.encoder.blocks.2.norm2.weight: mean diff = 0.008163\n",
      "model.encoder.blocks.2.norm2.bias: mean diff = 0.008442\n",
      "model.encoder.blocks.2.mlp.fc1.weight: mean diff = 0.008008\n",
      "model.encoder.blocks.2.mlp.fc1.bias: mean diff = 0.004350\n",
      "model.encoder.blocks.2.mlp.fc2.weight: mean diff = 0.008403\n",
      "model.encoder.blocks.2.mlp.fc2.bias: mean diff = 0.004119\n",
      "model.encoder.blocks.3.norm1.weight: mean diff = 0.024210\n",
      "model.encoder.blocks.3.norm1.bias: mean diff = 0.008075\n",
      "model.encoder.blocks.3.attn.q_bias: mean diff = 0.008753\n",
      "model.encoder.blocks.3.attn.v_bias: mean diff = 0.003041\n",
      "model.encoder.blocks.3.attn.qkv.weight: mean diff = 0.007718\n",
      "model.encoder.blocks.3.attn.proj.weight: mean diff = 0.007132\n",
      "model.encoder.blocks.3.attn.proj.bias: mean diff = 0.004209\n",
      "model.encoder.blocks.3.norm2.weight: mean diff = 0.009572\n",
      "model.encoder.blocks.3.norm2.bias: mean diff = 0.008955\n",
      "model.encoder.blocks.3.mlp.fc1.weight: mean diff = 0.008143\n",
      "model.encoder.blocks.3.mlp.fc1.bias: mean diff = 0.004152\n",
      "model.encoder.blocks.3.mlp.fc2.weight: mean diff = 0.008227\n",
      "model.encoder.blocks.3.mlp.fc2.bias: mean diff = 0.003421\n",
      "model.encoder.blocks.4.norm1.weight: mean diff = 0.014862\n",
      "model.encoder.blocks.4.norm1.bias: mean diff = 0.006256\n",
      "model.encoder.blocks.4.attn.q_bias: mean diff = 0.007826\n",
      "model.encoder.blocks.4.attn.v_bias: mean diff = 0.002744\n",
      "model.encoder.blocks.4.attn.qkv.weight: mean diff = 0.008095\n",
      "model.encoder.blocks.4.attn.proj.weight: mean diff = 0.007445\n",
      "model.encoder.blocks.4.attn.proj.bias: mean diff = 0.003637\n",
      "model.encoder.blocks.4.norm2.weight: mean diff = 0.010687\n",
      "model.encoder.blocks.4.norm2.bias: mean diff = 0.006837\n",
      "model.encoder.blocks.4.mlp.fc1.weight: mean diff = 0.008304\n",
      "model.encoder.blocks.4.mlp.fc1.bias: mean diff = 0.003979\n",
      "model.encoder.blocks.4.mlp.fc2.weight: mean diff = 0.008322\n",
      "model.encoder.blocks.4.mlp.fc2.bias: mean diff = 0.003251\n",
      "model.encoder.blocks.5.norm1.weight: mean diff = 0.015071\n",
      "model.encoder.blocks.5.norm1.bias: mean diff = 0.007024\n",
      "model.encoder.blocks.5.attn.q_bias: mean diff = 0.006211\n",
      "model.encoder.blocks.5.attn.v_bias: mean diff = 0.002752\n",
      "model.encoder.blocks.5.attn.qkv.weight: mean diff = 0.008135\n",
      "model.encoder.blocks.5.attn.proj.weight: mean diff = 0.007384\n",
      "model.encoder.blocks.5.attn.proj.bias: mean diff = 0.003489\n",
      "model.encoder.blocks.5.norm2.weight: mean diff = 0.009168\n",
      "model.encoder.blocks.5.norm2.bias: mean diff = 0.006784\n",
      "model.encoder.blocks.5.mlp.fc1.weight: mean diff = 0.008266\n",
      "model.encoder.blocks.5.mlp.fc1.bias: mean diff = 0.004113\n",
      "model.encoder.blocks.5.mlp.fc2.weight: mean diff = 0.008260\n",
      "model.encoder.blocks.5.mlp.fc2.bias: mean diff = 0.003733\n",
      "model.encoder.blocks.6.norm1.weight: mean diff = 0.016248\n",
      "model.encoder.blocks.6.norm1.bias: mean diff = 0.007962\n",
      "model.encoder.blocks.6.attn.q_bias: mean diff = 0.006112\n",
      "model.encoder.blocks.6.attn.v_bias: mean diff = 0.002437\n",
      "model.encoder.blocks.6.attn.qkv.weight: mean diff = 0.008012\n",
      "model.encoder.blocks.6.attn.proj.weight: mean diff = 0.007046\n",
      "model.encoder.blocks.6.attn.proj.bias: mean diff = 0.003107\n",
      "model.encoder.blocks.6.norm2.weight: mean diff = 0.009849\n",
      "model.encoder.blocks.6.norm2.bias: mean diff = 0.006907\n",
      "model.encoder.blocks.6.mlp.fc1.weight: mean diff = 0.008311\n",
      "model.encoder.blocks.6.mlp.fc1.bias: mean diff = 0.003828\n",
      "model.encoder.blocks.6.mlp.fc2.weight: mean diff = 0.008179\n",
      "model.encoder.blocks.6.mlp.fc2.bias: mean diff = 0.003291\n",
      "model.encoder.blocks.7.norm1.weight: mean diff = 0.017593\n",
      "model.encoder.blocks.7.norm1.bias: mean diff = 0.005134\n",
      "model.encoder.blocks.7.attn.q_bias: mean diff = 0.005650\n",
      "model.encoder.blocks.7.attn.v_bias: mean diff = 0.002477\n",
      "model.encoder.blocks.7.attn.qkv.weight: mean diff = 0.007894\n",
      "model.encoder.blocks.7.attn.proj.weight: mean diff = 0.006858\n",
      "model.encoder.blocks.7.attn.proj.bias: mean diff = 0.002664\n",
      "model.encoder.blocks.7.norm2.weight: mean diff = 0.009778\n",
      "model.encoder.blocks.7.norm2.bias: mean diff = 0.006186\n",
      "model.encoder.blocks.7.mlp.fc1.weight: mean diff = 0.008519\n",
      "model.encoder.blocks.7.mlp.fc1.bias: mean diff = 0.003691\n",
      "model.encoder.blocks.7.mlp.fc2.weight: mean diff = 0.008175\n",
      "model.encoder.blocks.7.mlp.fc2.bias: mean diff = 0.002516\n",
      "model.encoder.blocks.8.norm1.weight: mean diff = 0.019159\n",
      "model.encoder.blocks.8.norm1.bias: mean diff = 0.004583\n",
      "model.encoder.blocks.8.attn.q_bias: mean diff = 0.005726\n",
      "model.encoder.blocks.8.attn.v_bias: mean diff = 0.002154\n",
      "model.encoder.blocks.8.attn.qkv.weight: mean diff = 0.007914\n",
      "model.encoder.blocks.8.attn.proj.weight: mean diff = 0.006861\n",
      "model.encoder.blocks.8.attn.proj.bias: mean diff = 0.002710\n",
      "model.encoder.blocks.8.norm2.weight: mean diff = 0.009182\n",
      "model.encoder.blocks.8.norm2.bias: mean diff = 0.005031\n",
      "model.encoder.blocks.8.mlp.fc1.weight: mean diff = 0.008811\n",
      "model.encoder.blocks.8.mlp.fc1.bias: mean diff = 0.003810\n",
      "model.encoder.blocks.8.mlp.fc2.weight: mean diff = 0.008214\n",
      "model.encoder.blocks.8.mlp.fc2.bias: mean diff = 0.002427\n",
      "model.encoder.blocks.9.norm1.weight: mean diff = 0.018539\n",
      "model.encoder.blocks.9.norm1.bias: mean diff = 0.004062\n",
      "model.encoder.blocks.9.attn.q_bias: mean diff = 0.005674\n",
      "model.encoder.blocks.9.attn.v_bias: mean diff = 0.002108\n",
      "model.encoder.blocks.9.attn.qkv.weight: mean diff = 0.007946\n",
      "model.encoder.blocks.9.attn.proj.weight: mean diff = 0.006753\n",
      "model.encoder.blocks.9.attn.proj.bias: mean diff = 0.002933\n",
      "model.encoder.blocks.9.norm2.weight: mean diff = 0.008389\n",
      "model.encoder.blocks.9.norm2.bias: mean diff = 0.003412\n",
      "model.encoder.blocks.9.mlp.fc1.weight: mean diff = 0.008949\n",
      "model.encoder.blocks.9.mlp.fc1.bias: mean diff = 0.003873\n",
      "model.encoder.blocks.9.mlp.fc2.weight: mean diff = 0.008161\n",
      "model.encoder.blocks.9.mlp.fc2.bias: mean diff = 0.003028\n",
      "model.encoder.blocks.10.norm1.weight: mean diff = 0.017183\n",
      "model.encoder.blocks.10.norm1.bias: mean diff = 0.004157\n",
      "model.encoder.blocks.10.attn.q_bias: mean diff = 0.005866\n",
      "model.encoder.blocks.10.attn.v_bias: mean diff = 0.001970\n",
      "model.encoder.blocks.10.attn.qkv.weight: mean diff = 0.008011\n",
      "model.encoder.blocks.10.attn.proj.weight: mean diff = 0.006549\n",
      "model.encoder.blocks.10.attn.proj.bias: mean diff = 0.002959\n",
      "model.encoder.blocks.10.norm2.weight: mean diff = 0.008069\n",
      "model.encoder.blocks.10.norm2.bias: mean diff = 0.003686\n",
      "model.encoder.blocks.10.mlp.fc1.weight: mean diff = 0.008925\n",
      "model.encoder.blocks.10.mlp.fc1.bias: mean diff = 0.004349\n",
      "model.encoder.blocks.10.mlp.fc2.weight: mean diff = 0.008291\n",
      "model.encoder.blocks.10.mlp.fc2.bias: mean diff = 0.003533\n",
      "model.encoder.blocks.11.norm1.weight: mean diff = 0.013719\n",
      "model.encoder.blocks.11.norm1.bias: mean diff = 0.003790\n",
      "model.encoder.blocks.11.attn.q_bias: mean diff = 0.005193\n",
      "model.encoder.blocks.11.attn.v_bias: mean diff = 0.002051\n",
      "model.encoder.blocks.11.attn.qkv.weight: mean diff = 0.007769\n",
      "model.encoder.blocks.11.attn.proj.weight: mean diff = 0.006111\n",
      "model.encoder.blocks.11.attn.proj.bias: mean diff = 0.003597\n",
      "model.encoder.blocks.11.norm2.weight: mean diff = 0.007919\n",
      "model.encoder.blocks.11.norm2.bias: mean diff = 0.003467\n",
      "model.encoder.blocks.11.mlp.fc1.weight: mean diff = 0.008617\n",
      "model.encoder.blocks.11.mlp.fc1.bias: mean diff = 0.004911\n",
      "model.encoder.blocks.11.mlp.fc2.weight: mean diff = 0.005941\n",
      "model.encoder.blocks.11.mlp.fc2.bias: mean diff = 0.004826\n",
      "model.encoder.norm.weight: mean diff = 0.023641\n",
      "model.encoder.norm.bias: mean diff = 0.006445\n",
      "model.head_exp.head.weight: mean diff = 0.002258\n",
      "model.head_exp.head.bias: mean diff = 0.004678\n"
     ]
    }
   ],
   "source": [
    "diffs = {}\n",
    "for (name1, param1), (name2, param2) in zip(model.named_parameters(), pretrain_model.named_parameters()):\n",
    "    assert name1 == name2, f\"Layer mismatch: {name1} vs {name2}\"\n",
    "    if not torch.allclose(param1, param2, atol=1e-6):\n",
    "        diffs[name1] = (param1.detach().cpu(), param2.detach().cpu())\n",
    "\n",
    "print(f\"Found {len(diffs)} layers with differences:\")\n",
    "for name, (curr, pre) in diffs.items():\n",
    "    print(f\"{name}: mean diff = {(curr - pre).abs().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a209b0f-03a7-44ab-ba9e-320d7a50b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble_weights(model, seed=None):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            # Replace with random values of the same shape\n",
    "            param.data = torch.randn_like(param.data)\n",
    "    print(\"Weights scrambled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af32dc6e-4e7d-46d2-a6c6-64584b35a2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights scrambled!\n"
     ]
    }
   ],
   "source": [
    "scramble_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbc9a54f-8724-4414-b787-cf7ee855269e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token: torch.Size([1, 1, 768]), mean=-0.0399, std=0.9752\n",
      "region_embed.embed.weight: torch.Size([768, 283]), mean=-0.0020, std=1.0020\n",
      "region_embed.embed.bias: torch.Size([768]), mean=-0.0280, std=0.9830\n",
      "encoder.blocks.0.norm1.weight: torch.Size([768]), mean=-0.0419, std=1.0177\n",
      "encoder.blocks.0.norm1.bias: torch.Size([768]), mean=0.0102, std=0.9588\n",
      "encoder.blocks.0.attn.q_bias: torch.Size([768]), mean=-0.0578, std=1.0110\n",
      "encoder.blocks.0.attn.v_bias: torch.Size([768]), mean=0.0172, std=1.0471\n",
      "encoder.blocks.0.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0006, std=0.9999\n",
      "encoder.blocks.0.attn.proj.weight: torch.Size([768, 768]), mean=0.0011, std=0.9995\n",
      "encoder.blocks.0.attn.proj.bias: torch.Size([768]), mean=0.0100, std=0.9812\n",
      "encoder.blocks.0.norm2.weight: torch.Size([768]), mean=-0.0178, std=0.9605\n",
      "encoder.blocks.0.norm2.bias: torch.Size([768]), mean=-0.0198, std=0.9767\n",
      "encoder.blocks.0.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0003, std=1.0003\n",
      "encoder.blocks.0.mlp.fc1.bias: torch.Size([3072]), mean=0.0016, std=0.9801\n",
      "encoder.blocks.0.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0005, std=0.9999\n",
      "encoder.blocks.0.mlp.fc2.bias: torch.Size([768]), mean=0.0051, std=0.9889\n",
      "encoder.blocks.1.norm1.weight: torch.Size([768]), mean=0.0068, std=1.0581\n",
      "encoder.blocks.1.norm1.bias: torch.Size([768]), mean=-0.0539, std=0.9799\n",
      "encoder.blocks.1.attn.q_bias: torch.Size([768]), mean=-0.0067, std=1.0449\n",
      "encoder.blocks.1.attn.v_bias: torch.Size([768]), mean=0.0210, std=0.9943\n",
      "encoder.blocks.1.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0010, std=0.9998\n",
      "encoder.blocks.1.attn.proj.weight: torch.Size([768, 768]), mean=-0.0001, std=0.9988\n",
      "encoder.blocks.1.attn.proj.bias: torch.Size([768]), mean=0.0166, std=1.0044\n",
      "encoder.blocks.1.norm2.weight: torch.Size([768]), mean=-0.0424, std=0.9917\n",
      "encoder.blocks.1.norm2.bias: torch.Size([768]), mean=0.0009, std=0.9932\n",
      "encoder.blocks.1.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0000, std=1.0005\n",
      "encoder.blocks.1.mlp.fc1.bias: torch.Size([3072]), mean=0.0187, std=1.0105\n",
      "encoder.blocks.1.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0001, std=1.0001\n",
      "encoder.blocks.1.mlp.fc2.bias: torch.Size([768]), mean=-0.0066, std=0.9965\n",
      "encoder.blocks.2.norm1.weight: torch.Size([768]), mean=0.0097, std=0.9696\n",
      "encoder.blocks.2.norm1.bias: torch.Size([768]), mean=0.0162, std=0.9653\n",
      "encoder.blocks.2.attn.q_bias: torch.Size([768]), mean=0.0434, std=1.0041\n",
      "encoder.blocks.2.attn.v_bias: torch.Size([768]), mean=-0.0110, std=1.0412\n",
      "encoder.blocks.2.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0010, std=1.0007\n",
      "encoder.blocks.2.attn.proj.weight: torch.Size([768, 768]), mean=0.0010, std=1.0008\n",
      "encoder.blocks.2.attn.proj.bias: torch.Size([768]), mean=0.0903, std=0.9888\n",
      "encoder.blocks.2.norm2.weight: torch.Size([768]), mean=0.0466, std=0.9719\n",
      "encoder.blocks.2.norm2.bias: torch.Size([768]), mean=0.0072, std=1.0022\n",
      "encoder.blocks.2.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0006, std=1.0005\n",
      "encoder.blocks.2.mlp.fc1.bias: torch.Size([3072]), mean=0.0115, std=1.0062\n",
      "encoder.blocks.2.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0002, std=0.9998\n",
      "encoder.blocks.2.mlp.fc2.bias: torch.Size([768]), mean=0.0231, std=0.9971\n",
      "encoder.blocks.3.norm1.weight: torch.Size([768]), mean=0.0238, std=0.9969\n",
      "encoder.blocks.3.norm1.bias: torch.Size([768]), mean=0.0305, std=1.0078\n",
      "encoder.blocks.3.attn.q_bias: torch.Size([768]), mean=-0.0406, std=0.9598\n",
      "encoder.blocks.3.attn.v_bias: torch.Size([768]), mean=0.0049, std=1.0251\n",
      "encoder.blocks.3.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0011, std=0.9995\n",
      "encoder.blocks.3.attn.proj.weight: torch.Size([768, 768]), mean=-0.0001, std=1.0012\n",
      "encoder.blocks.3.attn.proj.bias: torch.Size([768]), mean=0.0752, std=1.0026\n",
      "encoder.blocks.3.norm2.weight: torch.Size([768]), mean=-0.0533, std=1.0292\n",
      "encoder.blocks.3.norm2.bias: torch.Size([768]), mean=-0.0823, std=1.0306\n",
      "encoder.blocks.3.mlp.fc1.weight: torch.Size([3072, 768]), mean=0.0006, std=1.0000\n",
      "encoder.blocks.3.mlp.fc1.bias: torch.Size([3072]), mean=0.0158, std=1.0273\n",
      "encoder.blocks.3.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0008, std=0.9994\n",
      "encoder.blocks.3.mlp.fc2.bias: torch.Size([768]), mean=-0.0206, std=1.0261\n",
      "encoder.blocks.4.norm1.weight: torch.Size([768]), mean=-0.0182, std=0.9801\n",
      "encoder.blocks.4.norm1.bias: torch.Size([768]), mean=0.0157, std=0.9978\n",
      "encoder.blocks.4.attn.q_bias: torch.Size([768]), mean=-0.0183, std=0.9976\n",
      "encoder.blocks.4.attn.v_bias: torch.Size([768]), mean=0.0021, std=0.9745\n",
      "encoder.blocks.4.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0017, std=0.9998\n",
      "encoder.blocks.4.attn.proj.weight: torch.Size([768, 768]), mean=0.0011, std=1.0002\n",
      "encoder.blocks.4.attn.proj.bias: torch.Size([768]), mean=0.0363, std=1.0207\n",
      "encoder.blocks.4.norm2.weight: torch.Size([768]), mean=-0.0162, std=0.9899\n",
      "encoder.blocks.4.norm2.bias: torch.Size([768]), mean=-0.0033, std=1.0232\n",
      "encoder.blocks.4.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0015, std=0.9996\n",
      "encoder.blocks.4.mlp.fc1.bias: torch.Size([3072]), mean=0.0324, std=0.9963\n",
      "encoder.blocks.4.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0006, std=1.0005\n",
      "encoder.blocks.4.mlp.fc2.bias: torch.Size([768]), mean=-0.0244, std=1.0246\n",
      "encoder.blocks.5.norm1.weight: torch.Size([768]), mean=0.0766, std=1.0263\n",
      "encoder.blocks.5.norm1.bias: torch.Size([768]), mean=-0.0581, std=0.9854\n",
      "encoder.blocks.5.attn.q_bias: torch.Size([768]), mean=-0.0884, std=0.9774\n",
      "encoder.blocks.5.attn.v_bias: torch.Size([768]), mean=-0.0137, std=0.9592\n",
      "encoder.blocks.5.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0011, std=0.9997\n",
      "encoder.blocks.5.attn.proj.weight: torch.Size([768, 768]), mean=0.0004, std=1.0018\n",
      "encoder.blocks.5.attn.proj.bias: torch.Size([768]), mean=0.0059, std=0.9886\n",
      "encoder.blocks.5.norm2.weight: torch.Size([768]), mean=-0.0188, std=0.9820\n",
      "encoder.blocks.5.norm2.bias: torch.Size([768]), mean=0.0214, std=0.9833\n",
      "encoder.blocks.5.mlp.fc1.weight: torch.Size([3072, 768]), mean=0.0011, std=0.9993\n",
      "encoder.blocks.5.mlp.fc1.bias: torch.Size([3072]), mean=-0.0025, std=1.0126\n",
      "encoder.blocks.5.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0003, std=0.9996\n",
      "encoder.blocks.5.mlp.fc2.bias: torch.Size([768]), mean=-0.0676, std=0.9985\n",
      "encoder.blocks.6.norm1.weight: torch.Size([768]), mean=-0.0242, std=0.9925\n",
      "encoder.blocks.6.norm1.bias: torch.Size([768]), mean=0.0708, std=1.0140\n",
      "encoder.blocks.6.attn.q_bias: torch.Size([768]), mean=-0.0507, std=0.9750\n",
      "encoder.blocks.6.attn.v_bias: torch.Size([768]), mean=-0.0092, std=1.0175\n",
      "encoder.blocks.6.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0002, std=1.0008\n",
      "encoder.blocks.6.attn.proj.weight: torch.Size([768, 768]), mean=0.0009, std=1.0002\n",
      "encoder.blocks.6.attn.proj.bias: torch.Size([768]), mean=0.0045, std=1.0316\n",
      "encoder.blocks.6.norm2.weight: torch.Size([768]), mean=-0.0155, std=1.0118\n",
      "encoder.blocks.6.norm2.bias: torch.Size([768]), mean=-0.0208, std=0.9933\n",
      "encoder.blocks.6.mlp.fc1.weight: torch.Size([3072, 768]), mean=0.0005, std=1.0009\n",
      "encoder.blocks.6.mlp.fc1.bias: torch.Size([3072]), mean=0.0039, std=1.0121\n",
      "encoder.blocks.6.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0000, std=0.9993\n",
      "encoder.blocks.6.mlp.fc2.bias: torch.Size([768]), mean=0.0036, std=1.0230\n",
      "encoder.blocks.7.norm1.weight: torch.Size([768]), mean=0.0238, std=0.9769\n",
      "encoder.blocks.7.norm1.bias: torch.Size([768]), mean=-0.0042, std=1.0244\n",
      "encoder.blocks.7.attn.q_bias: torch.Size([768]), mean=0.0007, std=1.0265\n",
      "encoder.blocks.7.attn.v_bias: torch.Size([768]), mean=-0.0385, std=1.0103\n",
      "encoder.blocks.7.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0007, std=0.9995\n",
      "encoder.blocks.7.attn.proj.weight: torch.Size([768, 768]), mean=0.0005, std=1.0005\n",
      "encoder.blocks.7.attn.proj.bias: torch.Size([768]), mean=0.0302, std=1.0037\n",
      "encoder.blocks.7.norm2.weight: torch.Size([768]), mean=0.0203, std=0.9876\n",
      "encoder.blocks.7.norm2.bias: torch.Size([768]), mean=-0.0167, std=1.0043\n",
      "encoder.blocks.7.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0002, std=1.0000\n",
      "encoder.blocks.7.mlp.fc1.bias: torch.Size([3072]), mean=0.0100, std=0.9893\n",
      "encoder.blocks.7.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0008, std=1.0003\n",
      "encoder.blocks.7.mlp.fc2.bias: torch.Size([768]), mean=-0.0138, std=1.0241\n",
      "encoder.blocks.8.norm1.weight: torch.Size([768]), mean=-0.0112, std=1.0018\n",
      "encoder.blocks.8.norm1.bias: torch.Size([768]), mean=0.0156, std=1.0218\n",
      "encoder.blocks.8.attn.q_bias: torch.Size([768]), mean=0.0101, std=1.0314\n",
      "encoder.blocks.8.attn.v_bias: torch.Size([768]), mean=0.0327, std=1.0033\n",
      "encoder.blocks.8.attn.qkv.weight: torch.Size([2304, 768]), mean=0.0007, std=0.9997\n",
      "encoder.blocks.8.attn.proj.weight: torch.Size([768, 768]), mean=-0.0003, std=1.0001\n",
      "encoder.blocks.8.attn.proj.bias: torch.Size([768]), mean=-0.0174, std=0.9626\n",
      "encoder.blocks.8.norm2.weight: torch.Size([768]), mean=0.0171, std=0.9419\n",
      "encoder.blocks.8.norm2.bias: torch.Size([768]), mean=-0.0322, std=0.9833\n",
      "encoder.blocks.8.mlp.fc1.weight: torch.Size([3072, 768]), mean=0.0009, std=1.0003\n",
      "encoder.blocks.8.mlp.fc1.bias: torch.Size([3072]), mean=-0.0241, std=0.9995\n",
      "encoder.blocks.8.mlp.fc2.weight: torch.Size([768, 3072]), mean=-0.0009, std=1.0001\n",
      "encoder.blocks.8.mlp.fc2.bias: torch.Size([768]), mean=0.0213, std=1.0715\n",
      "encoder.blocks.9.norm1.weight: torch.Size([768]), mean=-0.0261, std=0.9772\n",
      "encoder.blocks.9.norm1.bias: torch.Size([768]), mean=-0.0098, std=1.0205\n",
      "encoder.blocks.9.attn.q_bias: torch.Size([768]), mean=-0.0127, std=1.0180\n",
      "encoder.blocks.9.attn.v_bias: torch.Size([768]), mean=0.0722, std=1.0126\n",
      "encoder.blocks.9.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0008, std=1.0007\n",
      "encoder.blocks.9.attn.proj.weight: torch.Size([768, 768]), mean=-0.0005, std=1.0001\n",
      "encoder.blocks.9.attn.proj.bias: torch.Size([768]), mean=0.0429, std=0.9799\n",
      "encoder.blocks.9.norm2.weight: torch.Size([768]), mean=0.0119, std=0.9979\n",
      "encoder.blocks.9.norm2.bias: torch.Size([768]), mean=0.0126, std=0.9683\n",
      "encoder.blocks.9.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0010, std=1.0000\n",
      "encoder.blocks.9.mlp.fc1.bias: torch.Size([3072]), mean=0.0092, std=1.0084\n",
      "encoder.blocks.9.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0003, std=1.0004\n",
      "encoder.blocks.9.mlp.fc2.bias: torch.Size([768]), mean=-0.0431, std=0.9817\n",
      "encoder.blocks.10.norm1.weight: torch.Size([768]), mean=-0.0022, std=0.9903\n",
      "encoder.blocks.10.norm1.bias: torch.Size([768]), mean=-0.0437, std=0.9831\n",
      "encoder.blocks.10.attn.q_bias: torch.Size([768]), mean=-0.0562, std=0.9980\n",
      "encoder.blocks.10.attn.v_bias: torch.Size([768]), mean=-0.1022, std=0.9867\n",
      "encoder.blocks.10.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0006, std=1.0007\n",
      "encoder.blocks.10.attn.proj.weight: torch.Size([768, 768]), mean=-0.0006, std=0.9986\n",
      "encoder.blocks.10.attn.proj.bias: torch.Size([768]), mean=0.0729, std=1.0245\n",
      "encoder.blocks.10.norm2.weight: torch.Size([768]), mean=0.0490, std=0.9770\n",
      "encoder.blocks.10.norm2.bias: torch.Size([768]), mean=0.0251, std=1.0103\n",
      "encoder.blocks.10.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0000, std=0.9997\n",
      "encoder.blocks.10.mlp.fc1.bias: torch.Size([3072]), mean=0.0051, std=1.0143\n",
      "encoder.blocks.10.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0013, std=1.0003\n",
      "encoder.blocks.10.mlp.fc2.bias: torch.Size([768]), mean=0.0084, std=0.9608\n",
      "encoder.blocks.11.norm1.weight: torch.Size([768]), mean=-0.0442, std=0.9861\n",
      "encoder.blocks.11.norm1.bias: torch.Size([768]), mean=-0.0072, std=1.0151\n",
      "encoder.blocks.11.attn.q_bias: torch.Size([768]), mean=-0.0324, std=0.9833\n",
      "encoder.blocks.11.attn.v_bias: torch.Size([768]), mean=0.0042, std=0.9760\n",
      "encoder.blocks.11.attn.qkv.weight: torch.Size([2304, 768]), mean=-0.0005, std=1.0001\n",
      "encoder.blocks.11.attn.proj.weight: torch.Size([768, 768]), mean=0.0003, std=1.0004\n",
      "encoder.blocks.11.attn.proj.bias: torch.Size([768]), mean=-0.0178, std=0.9883\n",
      "encoder.blocks.11.norm2.weight: torch.Size([768]), mean=0.0387, std=0.9785\n",
      "encoder.blocks.11.norm2.bias: torch.Size([768]), mean=-0.0222, std=0.9497\n",
      "encoder.blocks.11.mlp.fc1.weight: torch.Size([3072, 768]), mean=-0.0002, std=0.9998\n",
      "encoder.blocks.11.mlp.fc1.bias: torch.Size([3072]), mean=0.0012, std=1.0018\n",
      "encoder.blocks.11.mlp.fc2.weight: torch.Size([768, 3072]), mean=0.0013, std=1.0004\n",
      "encoder.blocks.11.mlp.fc2.bias: torch.Size([768]), mean=0.0214, std=0.9923\n",
      "encoder.norm.weight: torch.Size([768]), mean=-0.0429, std=1.0010\n",
      "encoder.norm.bias: torch.Size([768]), mean=-0.0483, std=0.9882\n",
      "head_exp.head.weight: torch.Size([2, 768]), mean=0.0242, std=0.9863\n",
      "head_exp.head.bias: torch.Size([2]), mean=0.0690, std=1.2375\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}, mean={param.data.mean():.4f}, std={param.data.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "731f4ff8-d27f-4d92-b669-55e18543d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_path = cfg.dataset.zarr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e17a1aa0-d7e3-41df-8d08-abd038f48e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs/home/asun/jin_lab/get/3_aggr_m23_finetune/aggr_multiome_m23.zarr'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zarr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20a0e2e0-f869-4596-9a9e-12769655ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "181e2444-9ddd-4b2a-87f9-68e3c4224b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try split by comma\n",
    "if isinstance(zarr_path, str):\n",
    "    zarr_path = zarr_path.split(\",\")\n",
    "self_zarr_path = zarr_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "573bf183-7c8b-4ae3-b572-fe4abcf93f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available celltypes from zarr paths by checking atpm group\n",
    "self_available_celltypes = []\n",
    "for zarr_path in self_zarr_path:\n",
    "    zarr_root = zarr.open(zarr_path, mode='r')\n",
    "    if 'atpm' in zarr_root:\n",
    "        self_available_celltypes.extend(list(zarr_root['atpm'].keys()))\n",
    "self_available_celltypes = list(set(self_available_celltypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "005e16f5-1c5e-4533-85c8-358d52906285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L2',\n",
       " 'L5 IT',\n",
       " 'Pvalb',\n",
       " 'L5 ET',\n",
       " 'L6b',\n",
       " 'VLMC',\n",
       " 'L5',\n",
       " 'Astro',\n",
       " 'Micro-PVM',\n",
       " 'OPC',\n",
       " 'L6 IT',\n",
       " 'Sst',\n",
       " 'L6 CT',\n",
       " 'Oligo',\n",
       " 'Vip',\n",
       " 'Endo',\n",
       " 'Peri',\n",
       " 'Lamp5',\n",
       " 'Meis2']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_available_celltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7441b41b-5484-45d4-991f-20f447044ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes = cfg.dataset.celltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e46b241d-b86b-4a88-ac99-db42429cca42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some requested celltypes were not found in the zarr files: {'L5/6 NP', 'L2/3 IT'}\n"
     ]
    }
   ],
   "source": [
    "if celltypes is not None:\n",
    "    requested_celltypes = celltypes.split(\",\")\n",
    "    self_celltypes = [ct for ct in requested_celltypes if ct in self_available_celltypes]\n",
    "    if len(self_celltypes) < len(requested_celltypes):\n",
    "        missing = set(requested_celltypes) - set(self_celltypes)\n",
    "        print(f\"Some requested celltypes were not found in the zarr files: {missing}\")\n",
    "else:\n",
    "    self_celltypes = self_available_celltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75a3111-20f7-48ad-a127-f83982d277fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = RegionZarrDataModule(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e483ed34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfg.task.layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c37664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(batch, name=\"batch\"):\n",
    "    print(f\"{name} type: {type(batch)}\")\n",
    "    \n",
    "    if isinstance(batch, dict):\n",
    "        for k, v in batch.items():\n",
    "            if hasattr(v, \"shape\"):\n",
    "                print(f\"  {k}: shape={tuple(v.shape)}, dtype={v.dtype}\")\n",
    "            else:\n",
    "                print(f\"  {k}: {type(v)}\")\n",
    "                \n",
    "    elif isinstance(batch, (list, tuple)):\n",
    "        for i, v in enumerate(batch):\n",
    "            if hasattr(v, \"shape\"):\n",
    "                print(f\"  [{i}]: shape={tuple(v.shape)}, dtype={v.dtype}\")\n",
    "            else:\n",
    "                print(f\"  [{i}]: {type(v)} {v}\")\n",
    "                \n",
    "    else:\n",
    "        print(\"Unknown batch format:\", batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c072278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<get_model.run_region.RegionZarrDataModule at 0x7f2c55f42d20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ed14706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'interpret'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.cfg.task.test_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e24723f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 1/2 [00:04<00:04,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:10<00:00,  5.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch keys: dict_keys(['region_motif', 'mask', 'gene_name', 'tss_peak', 'chromosome', 'peak_coord', 'all_tss_peak', 'strand', 'exp_label', 'celltype'])\n",
      "batch type: <class 'dict'>\n",
      "  region_motif: shape=(8, 200, 283), dtype=torch.float32\n",
      "  mask: shape=(8, 200, 2), dtype=torch.int8\n",
      "  gene_name: <class 'list'>\n",
      "  tss_peak: shape=(8,), dtype=torch.int64\n",
      "  chromosome: <class 'list'>\n",
      "  peak_coord: shape=(8, 200, 2), dtype=torch.int64\n",
      "  all_tss_peak: shape=(8, 200), dtype=torch.int64\n",
      "  strand: shape=(8,), dtype=torch.int64\n",
      "  exp_label: shape=(8, 200, 2), dtype=torch.float32\n",
      "  celltype: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "dm.setup(\"predict\")\n",
    "batch = next(iter(dm.predict_dataloader()))\n",
    "print(\"Batch keys:\", batch.keys())\n",
    "show_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bba2104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegionEmbed(\n",
      "  (embed): Linear(in_features=283, out_features=768, bias=True)\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.009)\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.018)\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.027)\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.036)\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.045)\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.055)\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.064)\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.073)\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.082)\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.091)\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "    (attn_drop): Dropout(p=0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.100)\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop1): Dropout(p=0, inplace=False)\n",
      "    (drop2): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n"
     ]
    }
   ],
   "source": [
    "layer_names = ['region_embed', 'encoder.blocks.0', 'encoder.blocks.1', 'encoder.blocks.2', 'encoder.blocks.3', 'encoder.blocks.4', \n",
    "                        'encoder.blocks.5', 'encoder.blocks.6', 'encoder.blocks.7', 'encoder.blocks.8', 'encoder.blocks.9', 'encoder.blocks.10',\n",
    "                        'encoder.blocks.11', 'encoder.norm']\n",
    "\n",
    "for layer_name in layer_names:\n",
    "    layer = model.model.get_submodule(layer_name)\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "365f9741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 2/15 [00:00<00:02,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n",
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 4/15 [00:00<00:02,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n",
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 6/15 [00:01<00:01,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n",
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 8/15 [00:01<00:01,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n",
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 9/15 [00:01<00:01,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 11/15 [00:02<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n",
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 13/15 [00:02<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n",
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15/15 [00:03<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX']\n",
      "Batch keys: dict_keys(['region_motif', 'mask', 'atpm', 'chromosome', 'peak_coord', 'exp_label', 'celltype'])\n",
      "region_motif torch.Size([8, 200, 283]) torch.float32\n",
      "mask torch.Size([8, 200, 2]) torch.int8\n",
      "atpm torch.Size([8, 200, 1]) torch.float32\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch keys:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(k, \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m, v\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "dm.setup(\"fit\")\n",
    "batch = next(iter(dm.train_dataloader()))\n",
    "print(\"Batch keys:\", batch.keys())\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac0db2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203553, 2)\n",
      "bool\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load a single array from a .npy file\n",
    "array = np.load('/gpfs/home/asun/jin_lab/get/web/get_figure_code/lentiMPRA/k562_count_10/k562_count_10.tss.npy')\n",
    "\n",
    "# Check the contents\n",
    "print(array.shape)\n",
    "print(array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "835cc6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True False]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [ True False]\n",
      " [False False]]\n"
     ]
    }
   ],
   "source": [
    "print(array[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e54f4009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['indices', 'indptr', 'format', 'shape', 'data']\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"/gpfs/home/asun/jin_lab/get/web/get_figure_code/lentiMPRA/k562_count_10/k562_count_10.watac.npz\")\n",
    "print(data.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5699cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197871,)\n"
     ]
    }
   ],
   "source": [
    "print(data[\"data\"].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
