{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/alsun/get/1_methyl_preprocess/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from gcell._settings import get_setting\n",
    "from preprocess_utils import (\n",
    "    add_atpm,\n",
    "    add_exp,\n",
    "    create_peak_motif,\n",
    "    download_motif,\n",
    "    get_motif,\n",
    "    query_motif,\n",
    ")\n",
    "\n",
    "annotation_dir = Path(get_setting('annotation_dir'))\n",
    "print(\"gcell currently using annotation directory:\", annotation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_bed_url = \"https://resources.altius.org/~jvierstra/projects/motif-clustering/releases/v1.0/hg38.archetype_motifs.v1.0.bed.gz\"\n",
    "motif_bed_index_url = \"https://resources.altius.org/~jvierstra/projects/motif-clustering/releases/v1.0/hg38.archetype_motifs.v1.0.bed.gz.tbi\"\n",
    "\n",
    "\n",
    "if (\n",
    "    motif_bed_url\n",
    "    and motif_bed_index_url\n",
    "    and not (\n",
    "        (annotation_dir / \"hg38.archetype_motifs.v1.0.bed.gz\").exists()\n",
    "        or (annotation_dir / \"hg38.archetype_motifs.v1.0.bed.gz.tbi\").exists()\n",
    "    )\n",
    "):\n",
    "    download_motif(motif_bed_url, motif_bed_index_url, motif_dir=annotation_dir)\n",
    "    motif_bed = str(annotation_dir / \"hg38.archetype_motifs.v1.0.bed.gz\")\n",
    "else:\n",
    "    motif_bed = str(annotation_dir / \"hg38.archetype_motifs.v1.0.bed.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_bed = \"l2-3_it.atac.bed\" # since all cell types share the same peak set, when querying motifs, we can just use one cell type to query motifs.\n",
    "peaks_motif = query_motif(peak_bed, motif_bed)\n",
    "get_motif_output = get_motif(peak_bed, peaks_motif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def create_peak_motif(peak_motif_bed, output_zarr, peak_bed):\n",
    "    \"\"\"\n",
    "    Create a peak motif zarr file from a peak motif bed file.\n",
    "\n",
    "    This function reads a peak motif bed file, pivots the data, and saves it to a zarr file.\n",
    "    The zarr file contains three datasets: 'data', 'peak_names', 'motif_names', and 'accessibility'.\n",
    "    The 'data' dataset is a sparse matrix containing the peak motif data.\n",
    "    The 'peak_names' dataset contains the peak names.\n",
    "    The 'motif_names' dataset contains the motif names.\n",
    "\n",
    "    Args:\n",
    "        peak_motif_bed (str): Path to the peak motif bed file.\n",
    "        output_zarr (str): Path to the output zarr file.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    motif_annotations = pd.read_excel('https://resources.altius.org/~jvierstra/projects/motif-clustering/releases/v1.0/motif_annotations.xlsx')\n",
    "    motif_cluster_ids = motif_annotations.Name.unique()\n",
    "    # Read the peak motif bed file\n",
    "    peak_motif = pd.read_csv(\n",
    "        peak_motif_bed,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=[\"Chromosome\", \"Start\", \"End\", \"Motif_cluster\", \"Score\"],\n",
    "    )\n",
    "\n",
    "    # Pivot the data\n",
    "    peak_motif_pivoted = peak_motif.pivot_table(\n",
    "        index=[\"Chromosome\", \"Start\", \"End\"],\n",
    "        columns=\"Motif_cluster\",\n",
    "        values=\"Score\",\n",
    "        fill_value=0,\n",
    "    )\n",
    "\n",
    "    peak_motif_pivoted.reset_index(inplace=True)\n",
    "    # add missing motif columns\n",
    "    for motif_cluster_id in motif_cluster_ids:\n",
    "        if motif_cluster_id not in peak_motif_pivoted.columns:\n",
    "            peak_motif_pivoted[motif_cluster_id] = 1\n",
    "    # Create the 'Name' column\n",
    "    peak_motif_pivoted[\"Name\"] = peak_motif_pivoted.apply(\n",
    "        lambda x: f'{x[\"Chromosome\"]}:{x[\"Start\"]}-{x[\"End\"]}', axis=1\n",
    "    )\n",
    "    peak_motif_pivoted = peak_motif_pivoted.drop(columns=[\"Chromosome\", \"Start\", \"End\"])\n",
    "\n",
    "    # Read the original peak bed file\n",
    "    original_peaks = pd.read_csv(\n",
    "        peak_bed, sep=\"\\t\", header=None, names=[\"Chromosome\", \"Start\", \"End\", \"Score\"]\n",
    "    )\n",
    "\n",
    "    # exclude chrM and chrY\n",
    "    original_peaks = original_peaks[~original_peaks.Chromosome.isin([\"chrM\", \"chrY\"])]\n",
    "    original_peaks[\"Name\"] = original_peaks.apply(\n",
    "        lambda x: f'{x[\"Chromosome\"]}:{x[\"Start\"]}-{x[\"End\"]}', axis=1\n",
    "    )\n",
    "    \n",
    "    new_columns = list(motif_cluster_ids) + [\"Name\"]\n",
    "\n",
    "    # sort motif columns\n",
    "    peak_motif_pivoted = peak_motif_pivoted[new_columns]\n",
    "\n",
    "    # Merge the pivoted data with the original peaks\n",
    "    merged_data = pd.merge(original_peaks, peak_motif_pivoted, on=\"Name\", how=\"left\")\n",
    "\n",
    "    # Fill NaN values with 0 for motif columns\n",
    "    motif_columns = [\n",
    "        col\n",
    "        for col in merged_data.columns\n",
    "        if col not in [\"Chromosome\", \"Start\", \"End\", \"Score\", \"Name\"]\n",
    "    ]\n",
    "    \n",
    "    merged_data[motif_columns] = merged_data[motif_columns].fillna(0)\n",
    "    peak_length = (merged_data.End - merged_data.Start).values / 400 # convert to kb\n",
    "    merged_data[motif_columns] = merged_data[motif_columns].div(peak_length, axis=0)\n",
    "    # Prepare data for zarr storage\n",
    "    name_values = list(merged_data[\"Name\"].values)\n",
    "    motif_values = motif_columns\n",
    "\n",
    "    # Create sparse matrix\n",
    "    motif_data_matrix = merged_data[motif_columns].values\n",
    "    # Open zarr store and save data\n",
    "    from numcodecs import Blosc\n",
    "\n",
    "    z = zarr.open(output_zarr, mode=\"w\")\n",
    "    z.create_dataset(\n",
    "        \"data\",\n",
    "        data=motif_data_matrix.data,\n",
    "        chunks=(1000, motif_data_matrix.shape[1]),\n",
    "        dtype=np.float32,\n",
    "        compressor=Blosc(cname=\"zstd\", clevel=3, shuffle=Blosc.BITSHUFFLE),\n",
    "        shape=motif_data_matrix.shape,\n",
    "    )\n",
    "    z.create_dataset(\"peak_names\", data=name_values)\n",
    "    z.create_dataset(\"motif_names\", data=motif_values)\n",
    "\n",
    "    print(f\"Peak motif data saved to {output_zarr}\")\n",
    "\n",
    "create_peak_motif(get_motif_output, \"aggr_multiome.zarr\", peak_bed) # all cell types will later be added to the same zarr file as we use the same peak set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type in celltype_for_modeling:\n",
    "    add_atpm(\n",
    "        \"aggr_multiome.zarr\",\n",
    "        f\"{cell_type.replace(\" \", \"_\").replace(\"/\", \"-\").lower()}.atac.bed\",\n",
    "        cell_type,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
